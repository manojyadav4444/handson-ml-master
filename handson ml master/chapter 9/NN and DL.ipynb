{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\rajar\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.71799126e+01]\n",
      " [ 4.35986489e-01]\n",
      " [ 9.39679705e-03]\n",
      " [-1.06469184e-01]\n",
      " [ 6.41464353e-01]\n",
      " [-4.09536187e-06]\n",
      " [-3.77989258e-03]\n",
      " [-4.23745275e-01]\n",
      " [-4.37187374e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  theta_val = theta.eval() \n",
    "  \n",
    "print(theta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.34476576,  0.98214266, ..., -0.04959654,\n",
       "         1.05254828, -1.32783522],\n",
       "       [ 1.        ,  2.33223796, -0.60701891, ..., -0.09251223,\n",
       "         1.04318455, -1.32284391],\n",
       "       [ 1.        ,  1.7826994 ,  1.85618152, ..., -0.02584253,\n",
       "         1.03850269, -1.33282653],\n",
       "       ...,\n",
       "       [ 1.        , -1.14259331, -0.92485123, ..., -0.0717345 ,\n",
       "         1.77823747, -0.8237132 ],\n",
       "       [ 1.        , -1.05458292, -0.84539315, ..., -0.09122515,\n",
       "         1.77823747, -0.87362627],\n",
       "       [ 1.        , -0.78012947, -1.00430931, ..., -0.04368215,\n",
       "         1.75014627, -0.83369581]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)), scaled_housing_data]\n",
    "scaled_housing_data_plus_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch  0  mse=  12.408014\n",
      " epoch  100  mse=  0.75519687\n",
      " epoch  200  mse=  0.5420874\n",
      " epoch  300  mse=  0.5331699\n",
      " epoch  400  mse=  0.53053814\n",
      " epoch  500  mse=  0.5287963\n",
      " epoch  600  mse=  0.527549\n",
      " epoch  700  mse=  0.52664965\n",
      " epoch  800  mse=  0.5260011\n",
      " epoch  900  mse=  0.52553326\n",
      "[[ 2.0685523e+00]\n",
      " [ 8.1063598e-01]\n",
      " [ 1.2685776e-01]\n",
      " [-2.0784086e-01]\n",
      " [ 2.4839850e-01]\n",
      " [-1.3083885e-03]\n",
      " [-3.9607048e-02]\n",
      " [-8.5861266e-01]\n",
      " [-8.2600272e-01]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"y_predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mean_squared_error\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  for epoch in range(n_epochs):\n",
    "    if epoch%100 == 0:\n",
    "      print(\" epoch \",epoch,\" mse= \",mse.eval())\n",
    "    sess.run(training_op)\n",
    "  \n",
    "  best_theta = theta.eval()\n",
    "  \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 12.408014\n",
      "Epoch 100 MSE = 0.75519687\n",
      "Epoch 200 MSE = 0.5420874\n",
      "Epoch 300 MSE = 0.53317\n",
      "Epoch 400 MSE = 0.53053814\n",
      "Epoch 500 MSE = 0.5287964\n",
      "Epoch 600 MSE = 0.527549\n",
      "Epoch 700 MSE = 0.5266497\n",
      "Epoch 800 MSE = 0.5260011\n",
      "Epoch 900 MSE = 0.5255332\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.1063598e-01]\n",
      " [ 1.2685777e-01]\n",
      " [-2.0784083e-01]\n",
      " [ 2.4839847e-01]\n",
      " [-1.3083883e-03]\n",
      " [-3.9607048e-02]\n",
      " [-8.5861266e-01]\n",
      " [-8.2600272e-01]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\") \n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") \n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\") \n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\") \n",
    "error = y_pred - y \n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess: \n",
    "  sess.run(init)\n",
    "  for epoch in range(n_epochs):\n",
    "    if epoch % 100 == 0:  \n",
    "      print(\"Epoch\", epoch, \"MSE =\", mse.eval())    \n",
    "    sess.run(training_op)\n",
    "  best_theta = theta.eval() \n",
    "  \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 12.408014\n",
      "Epoch 100 MSE = 0.75519687\n",
      "Epoch 200 MSE = 0.5420874\n",
      "Epoch 300 MSE = 0.53317\n",
      "Epoch 400 MSE = 0.53053814\n",
      "Epoch 500 MSE = 0.5287964\n",
      "Epoch 600 MSE = 0.527549\n",
      "Epoch 700 MSE = 0.5266497\n",
      "Epoch 800 MSE = 0.5260011\n",
      "Epoch 900 MSE = 0.5255332\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.1063598e-01]\n",
      " [ 1.2685777e-01]\n",
      " [-2.0784083e-01]\n",
      " [ 2.4839847e-01]\n",
      " [-1.3083883e-03]\n",
      " [-3.9607048e-02]\n",
      " [-8.5861266e-01]\n",
      " [-8.2600272e-01]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\") \n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") \n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\") \n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\") \n",
    "error = y_pred - y \n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess: \n",
    "  sess.run(init)\n",
    "  for epoch in range(n_epochs):\n",
    "    if epoch % 100 == 0:  \n",
    "      print(\"Epoch\", epoch, \"MSE =\", mse.eval())    \n",
    "    sess.run(training_op)\n",
    "  best_theta = theta.eval() \n",
    "  \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0877347 ],\n",
       "       [ 0.81425226],\n",
       "       [-0.0394018 ],\n",
       "       [-0.42498362],\n",
       "       [ 0.30571643],\n",
       "       [-0.08363095],\n",
       "       [-0.3432868 ],\n",
       "       [-1.0353643 ],\n",
       "       [-0.95280176]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_data(epoch, batch_index, batch_size):\n",
    "  np.random.seed(42)\n",
    "  indices = np.random.randint(m, size = batch_size)\n",
    "  X_batch = scaled_housing_data_plus_bias[indices]\n",
    "  y_batch = housing.target.reshape(-1,1)[indices]\n",
    "  return X_batch, y_batch\n",
    "   \n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  for epoch in range(n_epochs):\n",
    "    for batch_index in range(n_batches):\n",
    "      X_batch, y_batch = fetch_data(epoch, batch_index, batch_size)\n",
    "      sess.run(training_op, feed_dict = {X:X_batch, y:y_batch})\n",
    "  best_theta = theta.eval()\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161542\n",
      "Epoch 100 MSE = 0.7145004\n",
      "Epoch 200 MSE = 0.56670487\n",
      "Epoch 300 MSE = 0.55557173\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436363\n",
      "Epoch 600 MSE = 0.53962904\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.53406775\n",
      "Epoch 900 MSE = 0.5321473\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                       # not shown in the book\n",
    "learning_rate = 0.01                                                                  # not shown\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # not shown\n",
    "error = y_pred - y                                                                    # not shown\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
    "training_op = optimizer.minimize(mse)                                                 # not shown\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess: \n",
    "  sess.run(init)\n",
    "  for epoch in range(n_epochs):\n",
    "    for batch_index in range(n_batches):\n",
    "      X_batch, y_batch = fetch_data(epoch, batch_index, batch_size)\n",
    "      if batch_index%10 == 0:\n",
    "          summary_str = mse_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          step = epoch*n_batches + batch_index\n",
    "          file_writer.add_summary(summary_str, step)\n",
    "      sess.run(training_op, feed_dict = {X:X_batch, y:y_batch})\n",
    "  best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = 'X')\n",
    "\n",
    "w1  = tf.Variable(tf.random_normal((n_features, 1)), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name = 'weight2')\n",
    "b1 = tf.Variable(0.0, name = 'bias1')\n",
    "b2 = tf.Variable(0.0, name = 'bias2')\n",
    "\n",
    "z1 = tf.add(tf.matmul(X,w1), b1, name = 'z1')\n",
    "z2 = tf.add(tf.matmul(X,w2), b2, name = 'z2')\n",
    "\n",
    "relu1 = tf.maximum(z1, 0.0, name = \"relu1\")\n",
    "relu2 = tf.maximum(z2, 0.0, name = 'relu2')\n",
    "\n",
    "output = tf.add(relu1, relu2, name = 'output')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "  with tf.variable_scope('relu',reuse=True):\n",
    "    threshold = tf.get_variable('threshold')\n",
    "    m = int(X.get_shape()[1])\n",
    "    w = tf.Variable(tf.random_normal((m, 1)), name = \"weights\")\n",
    "    b = tf.Variable(0.0, name = 'biases')\n",
    "    z = tf.add(tf.matmul(X, w), b, name = 'z')\n",
    "    return tf.maximum(z, threshold, name='relu') \n",
    "\n",
    "n_features = 3\n",
    "\n",
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshold', shape=(), initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5) ]\n",
    "output = tf.add_n(relus, name='output')\n",
    "\n",
    "file_writer = tf.summary.FileWriter('logs/relu3', tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\"):\n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "relus = []\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "for relu_index in range(5): \n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
