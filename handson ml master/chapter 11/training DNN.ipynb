{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-79bb2d46ad41>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A79517860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A79517860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A79517860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A79517860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation = tf.nn.relu, kernel_initializer = he_init, name='hidden1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.maximum can only be used element-wise, while numpy.max and numpy.amax can be used on particular axes, or all elements.\n",
    "b = np.array([3, 6, 1])\n",
    " c = np.array([4, 2, 9])\n",
    " np.maximum(b, c)\n",
    "result----->array([4, 6, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04520A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04520A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04520A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04520A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A045D1A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A045D1A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A045D1A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A045D1A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A04576E10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation = leaky_relu, name='hidden1')\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name='hidden2')\n",
    "    logits = tf.layers.dense(hidden2, n_output, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28)/255.0\n",
    "X_test = X_test.astype(np.int32).reshape(-1, 28*28)/255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_val, X_train = X_train[:5000], X_train[5000:]\n",
    "y_val, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000018A03A48F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 28*28), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bn_params = {\n",
    "        'is_training':is_training,\n",
    "        'decay':0.9,\n",
    "        'updates_collections':None,\n",
    "        'scale':True\n",
    "    }\n",
    "    \n",
    "    hidden1 = fully_connected(X, n_hidden1, scope='hidden1', normalizer_fn = batch_norm, normalizer_params=bn_params )\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2', normalizer_fn=batch_norm, normalizer_params=bn_params)\n",
    "    logits = fully_connected(hidden2, n_outputs, scope='output', activation_fn=None, normalizer_fn=batch_norm, normalizer_params=bn_params)\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28)/255.0\n",
    "X_test = X_test.astype(np.int32).reshape(-1, 28*28)/255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  training accuracy  1.0  testing accuracy  0.9692\n",
      "1  training accuracy  1.0  testing accuracy  0.9765\n",
      "2  training accuracy  1.0  testing accuracy  0.9783\n",
      "3  training accuracy  0.98  testing accuracy  0.9798\n",
      "4  training accuracy  1.0  testing accuracy  0.9793\n",
      "5  training accuracy  1.0  testing accuracy  0.9801\n",
      "6  training accuracy  1.0  testing accuracy  0.9817\n",
      "7  training accuracy  1.0  testing accuracy  0.9814\n",
      "8  training accuracy  1.0  testing accuracy  0.9812\n",
      "9  training accuracy  1.0  testing accuracy  0.9811\n"
     ]
    }
   ],
   "source": [
    "n_epoch=20\n",
    "batch_size = 50\n",
    "m,n = X_train.shape\n",
    "n_batch = np.int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch():\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch()\n",
    "            sess.run(training_op, feed_dict={is_training:True, X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={is_training:False, X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={is_training:False, X:X_test, y:y_test})\n",
    "        \n",
    "        print(epoch,' training accuracy ',acc_train, ' testing accuracy ',acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, 'my_model_final_batch_norm.ckpt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "threshold = 1.0\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_grads_and_vars = [(tf.clip_by_value(grad, -threshold, threshold),var) for grad,var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=20\n",
    "batch_size = 50\n",
    "m,n = X_train.shape\n",
    "n_batch = np.int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch():\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch()\n",
    "            sess.run(training_op, feed_dict={is_training:True, X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={is_training:False, X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={is_training:False, X:X_test, y:y_test})\n",
    "        \n",
    "        print(epoch,' training accuracy ',acc_train, ' testing accuracy ',acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, 'my_model_final_grad_clipped.ckpt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "decay_steps = 10000\n",
    "decay_rate = 1/10\n",
    "global_step = tf.Variable(0, trainable = False)\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=20\n",
    "batch_size = 50\n",
    "m,n = X_train.shape\n",
    "n_batch = np.int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch():\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch()\n",
    "            sess.run(training_op, feed_dict={ X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={ X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={ X:X_test, y:y_test})\n",
    "        \n",
    "        print(epoch,' training accuracy ',acc_train, ' testing accuracy ',acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, 'my_model_final.ckpt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 28*28), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bn_params = {\n",
    "        'is_training':is_training,\n",
    "        'decay':0.9,\n",
    "        'updates_collections':None,\n",
    "        'scale':True\n",
    "    }\n",
    "    \n",
    "    hidden1 = fully_connected(X, n_hidden1, scope='hidden1', normalizer_fn = batch_norm, normalizer_params=bn_params )\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2', normalizer_fn=batch_norm, normalizer_params=bn_params)\n",
    "    logits = fully_connected(hidden2, n_outputs, scope='output', activation_fn=None, normalizer_fn=batch_norm, normalizer_params=bn_params)\n",
    "    \n",
    "    \n",
    "\n",
    "with tf.variable_scope('', default_name='', reuse=True):\n",
    "    weights1 = tf.get_variable('hidden1/weights')\n",
    "    weights2 = tf.get_variable('hidden2/weights')\n",
    "    \n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy,name='avg_entropy')\n",
    "    reg_loss = tf.reduce_sum(tf.abs(weights1)) + tf.reduce_sum(tf.abs(weights2))\n",
    "    loss = tf.add(base_loss, 0.1*reg_loss, name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=20\n",
    "batch_size = 50\n",
    "m,n = X_train.shape\n",
    "n_batch = np.int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch():\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch()\n",
    "            sess.run(training_op, feed_dict={is_training:True, X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={is_training:False, X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={is_training:False, X:X_test, y:y_test})\n",
    "        \n",
    "        print(epoch,' training accuracy ',acc_train, ' testing accuracy ',acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, 'my_model_final_l1_reg.ckpt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001\n",
    "\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation = tf.nn.relu, kernel_relularizer=tf.contrib.layers.l1_regularizer(scale)\n",
    ")\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name='hidden1')\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name = 'hidden2')\n",
    "    logits = my_dense_layer(hidden2, n_output, activation=None, name='output')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, 'xentropy')\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_loss, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=20\n",
    "batch_size = 50\n",
    "m,n = X_train.shape\n",
    "n_batch = np.int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch():\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batch):\n",
    "            X_batch, y_batch = fetch_batch()\n",
    "            sess.run(training_op, feed_dict={is_training:True, X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={is_training:False, X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={is_training:False, X:X_test, y:y_test})\n",
    "        \n",
    "        print(epoch,' training accuracy ',acc_train, ' testing accuracy ',acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, 'my_model_final_l1_reg_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
